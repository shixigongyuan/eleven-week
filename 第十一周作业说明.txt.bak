第十一周作业说明：
一、word embedding 词嵌入
词嵌入可以把单词保留词与词之间的关系,还可以达到降维的目的，one-hot方式保存的话，维度会非常高
查资料说 Word2Vec 目前比较流行且可以自动实现 1、单词语义相似性的度量 ；2、词汇的语义的类比

word embedding 处理步骤：
1、读取数据，直接读取 全宋词文本，不用下载
2、构建字典
3、生成一个batch 供skip-gram model 使用
4、定义权重、biases、损失函数、优化器等
5、开始训练



matplotlib 中文显示问题，我是先下载字体库，然后传到 本地虚拟机 matplotlib 字体库目录下，然后动态指定字体类型
会报 sequence index must be integer, not 'slice' ，索引搞错了，不能切片，换了一种方式 extend
报 no display name and no $DISPLAY environment variable ，
二、修改utils.py 数据处理脚本
添加生成一个batch数据的代码，参考 raw_rnn_in_tf.ipynb
1、先按照batch_size划分分区，分区连续 分区长度=单词列表长度/batch_size
2、然后取每个epoch,epoch 也是连续的 epoch ,每个epoch长度 为num_steps

三、修改model.py rnn的模型定义
网络模型构建：参考 https://blog.csdn.net/mydear_11000/article/details/52414342
https://blog.csdn.net/weiwei9363/article/details/78902455

四、train.py 修改
参考：https://blog.csdn.net/u013082989/article/details/73469095/

缺少一个 feed_dict定义

